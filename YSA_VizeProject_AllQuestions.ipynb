{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DFZcmh8PjoDm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.SORU İLE İLGİLİ KOD KISMI**"
      ],
      "metadata": {
        "id": "vo4Q6idWsxjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **4.1)**  SEED=1 iken\n",
        "\n"
      ],
      "metadata": {
        "id": "MmgJHl6yhtCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yapay sinir ağ modeli tanımlama kısmı(eğitimsiz şekilde ileri besleme işlemi yapıyor)"
      ],
      "metadata": {
        "id": "1jpa6IpMo0im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.hidden_layer = nn.Linear(input_size, hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def tanh(self, x):\n",
        "        return torch.tanh(x)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.tanh(self.hidden_layer(x))\n",
        "        y = self.sigmoid(self.output_layer(h))\n",
        "        return y\n",
        "\n",
        "# Seed: aynı rastgele sayılar üretmesini sağlamak\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# Input değerleri\n",
        "X = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]], dtype=torch.float32)\n",
        "\n",
        "# Weight ve bias\n",
        "input_size = 3\n",
        "hidden_size = 50\n",
        "output_size = 1\n",
        "\n",
        "# Model oluşturma\n",
        "model = MyNet(input_size, hidden_size, output_size)\n",
        "\n",
        "# Print model parameters\n",
        "print(\"Modelin parametreleri aşağıdaki şekildedir:\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.size())\n",
        "\n",
        "# girdi tensörü X ile ileri doğru yayılım (forward propagation) işlemi uygular ve çıktı tensörü y'yi hesaplar.\n",
        "y = model(X)\n",
        "\n",
        "# Print output\n",
        "print(\"Çıktı katmanı :\")\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTCql8I0hrfj",
        "outputId": "691183fa-5204-4b67-b861-1ae63d568846"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelin parametreleri aşağıdaki şekildedir:\n",
            "hidden_layer.weight torch.Size([50, 3])\n",
            "hidden_layer.bias torch.Size([50])\n",
            "output_layer.weight torch.Size([1, 50])\n",
            "output_layer.bias torch.Size([1])\n",
            "Çıktı katmanı :\n",
            "tensor([[0.4892],\n",
            "        [0.5566]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **4.2)**   SEED=190401083 iken (okul no)\n",
        "\n"
      ],
      "metadata": {
        "id": "jsEOe_32r03m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.hidden_layer = nn.Linear(input_size, hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def tanh(self, x):\n",
        "        return torch.tanh(x)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.tanh(self.hidden_layer(x))\n",
        "        y = self.sigmoid(self.output_layer(h))\n",
        "        return y\n",
        "\n",
        "# Seed: aynı rastgele sayılar üretmesini sağlamak\n",
        "torch.manual_seed(190401083)\n",
        "\n",
        "# Input değerleri\n",
        "X = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]], dtype=torch.float32)\n",
        "\n",
        "# Weight ve bias\n",
        "input_size = 3\n",
        "hidden_size = 50\n",
        "output_size = 1\n",
        "\n",
        "# Model oluşturma\n",
        "model = MyNet(input_size, hidden_size, output_size)\n",
        "\n",
        "# Print model parameters\n",
        "print(\"Modelin parametreleri aşağıdaki şekildedir:\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.size())\n",
        "\n",
        "# girdi tensörü X ile ileri doğru yayılım (forward propagation) işlemi uygular ve çıktı tensörü y'yi hesaplar.\n",
        "y = model(X)\n",
        "\n",
        "# Print output\n",
        "print(\"Çıktı katmanı :\")\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZO7l6w6n-KO",
        "outputId": "cd87da14-3cdf-4ce2-f6b7-96b19ca5a2af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelin parametreleri aşağıdaki şekildedir:\n",
            "hidden_layer.weight torch.Size([50, 3])\n",
            "hidden_layer.bias torch.Size([50])\n",
            "output_layer.weight torch.Size([1, 50])\n",
            "output_layer.bias torch.Size([1])\n",
            "Çıktı katmanı :\n",
            "tensor([[0.6837],\n",
            "        [0.6456]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.SORU İLE İLGİLİ KOD KISMI**"
      ],
      "metadata": {
        "id": "GD-7mY0jtqXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri setlerini google drive'a yükleyip oradan çektim"
      ],
      "metadata": {
        "id": "OdXJeRxvxAKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PjBPxQQhv-8",
        "outputId": "c79fd57a-b3a6-4b6e-d59e-fa3b8846868a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/YSA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2X0pHT0ihma",
        "outputId": "2720ed2e-5bfd-4c81-e35e-6e230c3d1567"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/YSA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQDsANQBjCqT",
        "outputId": "a724d766-699f-4904-ad00-73fbc811458c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 171\n",
            "28 -rw------- 1 root root 28143 Apr 14 08:04 checkpoint.pt\n",
            "48 -rw------- 1 root root 48288 Apr  7 09:47 cure_the_princess_test.csv\n",
            "77 -rw------- 1 root root 78178 Apr  7 09:47 cure_the_princess_train.csv\n",
            "20 -rw------- 1 root root 19721 Apr  7 09:47 cure_the_princess_validation.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verileri okuyor"
      ],
      "metadata": {
        "id": "kznh32K6jsia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"cure_the_princess_train.csv\")\n",
        "test = pd.read_csv(\"cure_the_princess_test.csv\")\n",
        "valid = pd.read_csv(\"cure_the_princess_validation.csv\")"
      ],
      "metadata": {
        "id": "rkRD65JJjcln"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Train\" adlı bir pandas DataFrame nesnesinin ilk beş satırını ekrana yazdırdım. (hedef sütun cured)"
      ],
      "metadata": {
        "id": "3knEWFnOj9nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mLLHmd4Dj2F-",
        "outputId": "e14ebbec-acae-4828-a398-a3df06a116da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Phoenix Feather  Unicorn Horn  Dragon's Blood  Mermaid Tears  Fairy Dust  \\\n",
              "0             18.8           1.5            19.7            1.1        19.5   \n",
              "1              6.0           3.8            12.4           16.9        13.0   \n",
              "2             22.4           7.9            28.6           11.2         5.4   \n",
              "3             10.8           4.6             5.1           16.7        20.8   \n",
              "4              3.7           5.7             9.0            3.3        17.4   \n",
              "\n",
              "   Goblin Toes  Witch's Brew  Griffin Claw  Troll Hair  Kraken Ink  \\\n",
              "0         30.1          16.5           9.9        27.3         1.8   \n",
              "1         12.6          17.0          25.4         7.7        14.6   \n",
              "2          9.3          11.5          10.7         9.4        11.1   \n",
              "3         27.1           7.8          15.5        34.0         7.6   \n",
              "4         33.3           7.6          20.1        11.5         6.1   \n",
              "\n",
              "   Minotaur Horn  Basilisk Scale  Chimera Fang  Cured  \n",
              "0           18.9            25.3           2.0      1  \n",
              "1            3.8            23.7          17.9      0  \n",
              "2           21.4            29.1           7.5      0  \n",
              "3           16.5            27.3           3.2      1  \n",
              "4            5.2             6.1           1.9      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-954266d3-906c-41a0-a875-490ef6759cf1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phoenix Feather</th>\n",
              "      <th>Unicorn Horn</th>\n",
              "      <th>Dragon's Blood</th>\n",
              "      <th>Mermaid Tears</th>\n",
              "      <th>Fairy Dust</th>\n",
              "      <th>Goblin Toes</th>\n",
              "      <th>Witch's Brew</th>\n",
              "      <th>Griffin Claw</th>\n",
              "      <th>Troll Hair</th>\n",
              "      <th>Kraken Ink</th>\n",
              "      <th>Minotaur Horn</th>\n",
              "      <th>Basilisk Scale</th>\n",
              "      <th>Chimera Fang</th>\n",
              "      <th>Cured</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>19.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>19.5</td>\n",
              "      <td>30.1</td>\n",
              "      <td>16.5</td>\n",
              "      <td>9.9</td>\n",
              "      <td>27.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>18.9</td>\n",
              "      <td>25.3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>12.4</td>\n",
              "      <td>16.9</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.6</td>\n",
              "      <td>17.0</td>\n",
              "      <td>25.4</td>\n",
              "      <td>7.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>3.8</td>\n",
              "      <td>23.7</td>\n",
              "      <td>17.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.4</td>\n",
              "      <td>7.9</td>\n",
              "      <td>28.6</td>\n",
              "      <td>11.2</td>\n",
              "      <td>5.4</td>\n",
              "      <td>9.3</td>\n",
              "      <td>11.5</td>\n",
              "      <td>10.7</td>\n",
              "      <td>9.4</td>\n",
              "      <td>11.1</td>\n",
              "      <td>21.4</td>\n",
              "      <td>29.1</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.8</td>\n",
              "      <td>4.6</td>\n",
              "      <td>5.1</td>\n",
              "      <td>16.7</td>\n",
              "      <td>20.8</td>\n",
              "      <td>27.1</td>\n",
              "      <td>7.8</td>\n",
              "      <td>15.5</td>\n",
              "      <td>34.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>16.5</td>\n",
              "      <td>27.3</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.7</td>\n",
              "      <td>5.7</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>17.4</td>\n",
              "      <td>33.3</td>\n",
              "      <td>7.6</td>\n",
              "      <td>20.1</td>\n",
              "      <td>11.5</td>\n",
              "      <td>6.1</td>\n",
              "      <td>5.2</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-954266d3-906c-41a0-a875-490ef6759cf1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-954266d3-906c-41a0-a875-490ef6759cf1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-954266d3-906c-41a0-a875-490ef6759cf1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cured sütunun veri tipini öğrenmek"
      ],
      "metadata": {
        "id": "RKIYezWYkXnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"Cured\"].dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQy-xUG9kNRC",
        "outputId": "75d9f219-68e4-4f4e-9b9b-a6a85df79204"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Cured\" sütunundaki benzersiz (unique) değerleri ekrana yazdırmak."
      ],
      "metadata": {
        "id": "MdYjrA4DkiL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"Cured\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FagB8z7Jkcc2",
        "outputId": "80d67528-7999-4744-94fe-3ad3c9f4c53e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaç adet benzersiz değer var bunu öğrenmek"
      ],
      "metadata": {
        "id": "XqkfUxh2klzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"Cured\"].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-wl5HG1knpq",
        "outputId": "f10370ef-0f5c-45d4-a598-20f738092b14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Veri setimiz 14 sütundan oluşuyor. 13\n",
        "sütun tanımlayıcı faktörler, son etiket ise hedef değişkenimiz. Bundan dolayı input değerimiz 13 oluyor.\n",
        "*   hidden_size1 ve hidden_size2 gizli katman nöron sayısı.\n",
        "*   output_size, ikili sınıflandırma ile çalıştığımız için 1.\n",
        "*   batch_size model eğitimi için(16)\n",
        "num_epochs model kaç iterasyonda eğitimi tamamlasın diye düşünüp verilir.\n",
        "*   patience, eğer validation verilerindeki loss değeri kaç defa artarsa model erken dursun yani earlystopping durumuna girsin.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VepPX14eoF3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Çok katmanlı algılayıcı (multilayer perceptron, MLP) modelini tanımlamak\n",
        "\n"
      ],
      "metadata": {
        "id": "EAEk9EgiwwCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer perceptron (MLP) modelini tanımlamak\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "AMWCVcDfoEyf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri kümesindeki verileri eğitim, test ve doğrulama kümelerine ayırmak"
      ],
      "metadata": {
        "id": "ueWDzvHy2Txp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train.iloc[:,:-1]\n",
        "train_y = train.iloc[:,-1]\n",
        "\n",
        "test_x = test.iloc[:,:-1]\n",
        "test_y = test.iloc[:,-1]\n",
        "\n",
        "valid_x = valid.iloc[:,:-1]\n",
        "valid_y = valid.iloc[:,-1]"
      ],
      "metadata": {
        "id": "6UA2p-LqhuQZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yapay sinir ağı modelinde kullanılacak katmanların boyutlarını belirlemek"
      ],
      "metadata": {
        "id": "-6Od3cGm2lm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 13\n",
        "hidden_size1 = 100\n",
        "hidden_size2 = 50\n",
        "output_size = 1"
      ],
      "metadata": {
        "id": "9961l-RVhWbD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "num_epochs = 1000\n",
        "patience = 1000"
      ],
      "metadata": {
        "id": "vv4ZS_abhkq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d605b44-5bee-45e3-cabc-5d8b85a0a0aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 727 µs (started: 2023-04-14 08:24:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod bloğu, PyTorch'un DataLoader sınıfını kullanarak verileri yüklemek ve eğitim, doğrulama ve test verileri için ayrı ayrı veri yükleyicileri oluşturmak için kullanılır. İlk önce, train, test ve validasyon verileri örneklenir ve her bir örnek (x, y) bir tuple olarak veri kümesine eklenir. Daha sonra, her veri kümesi (train, test, valid) için bir DataLoader oluşturulur, bu DataLoader verileri belirtilen batch boyutunda yükler ve verileri her bir eğitim döneminde karıştırır (shuffle=True). Böylece, modelin eğitimi için kullanılabilecek veri yükleyicileri oluşturulmuş olur."
      ],
      "metadata": {
        "id": "l576-uhk27cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = torch.tensor(np.array(train_x),dtype = torch.float32)\n",
        "train_y = torch.tensor(np.array(train_y),dtype = torch.float32).reshape(-1,1)\n",
        "dataset = [(train_x[i],train_y[i]) for i in range(len(train_x))]\n",
        "dataloader_train = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "test_x = torch.tensor(np.array(test_x),dtype = torch.float32)\n",
        "test_y = torch.tensor(np.array(test_y),dtype = torch.float32).reshape(-1,1)\n",
        "dataset = [(test_x[i],test_y[i]) for i in range(len(test_x))]\n",
        "dataloader_test = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "valid_x = torch.tensor(np.array(valid_x),dtype = torch.float32)\n",
        "valid_y = torch.tensor(np.array(valid_y),dtype = torch.float32).reshape(-1,1)\n",
        "dataset = [(valid_x[i],valid_y[i]) for i in range(len(valid_x))]\n",
        "dataloader_valid = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "9CWUuDMIhxaN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu eklenti, her hücrenin çalıştırılma süresini gösterir."
      ],
      "metadata": {
        "id": "e9Htv5lv3dTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime"
      ],
      "metadata": {
        "id": "lIb4DOrNsbUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU ile çalışma"
      ],
      "metadata": {
        "id": "ClepAp2KNHaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autotime\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "list_train_loss, list_val_loss = [], []\n",
        "best_val_loss = None\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_count = 0.0\n",
        "    for inputs, labels in dataloader_train:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward(torch.ones_like(loss))\n",
        "        optimizer.step()\n",
        "\n",
        "        train_count += 1.0\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for inputs, labels in dataloader_valid:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "    model.train()\n",
        "\n",
        "    train_loss /= train_count\n",
        "    val_loss /= len(dataloader_valid)\n",
        "\n",
        "    print(\"Epoch\", epoch, \"Training loss\", train_loss,\"Validation Loss :\",val_loss)\n",
        "    list_train_loss.append(train_loss)\n",
        "    list_val_loss.append(val_loss)\n",
        "\n",
        "   \n",
        "\n",
        "plt.plot(list_train_loss, label=\"Training loss\")\n",
        "plt.plot(list_val_loss, label=\"Validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kA2XiLI7NGBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autotime\n",
        "\n",
        "SEED = 190401083  \n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "input_size = 13\n",
        "hidden_size1 = 100\n",
        "hidden_size2 = 50\n",
        "output_size = 1\n",
        "\n",
        "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
        "\n",
        "#PyTorch modelinin eğitimi için kayıp fonksiyonunu ve optimize ediciyi belirlemek\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# Eğitim ve doğrulama kayıp değerlerini takip etmek ve en düşük doğrulama kayıp değerlerini belirlemek için gerekli değişkenleri tanımlar.\n",
        "list_train_loss, list_val_loss = [], []\n",
        "best_val_loss = None\n",
        "patience_counter = 0\n",
        "\n",
        "# Belirtilen sayıda epoch için modelin eğitimini gerçekleştiriyor.\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_count = 0.0\n",
        "    for inputs, labels in dataloader_train:\n",
        "        optimizer.zero_grad()   #gradyanları sıfırlıyoruz\n",
        "        outputs = model(inputs)   #model(inputs) ile girdileri modele veriyoruz ve çıktıları alıyoruz\n",
        "        loss = criterion(outputs, labels)  #çıktılar ve etiketler arasındaki kaybı hesaplıyoruz\n",
        "        loss.backward()  #gradyanları hesaplıyoruz\n",
        "        optimizer.step()  #parametreleri güncelliyoruz\n",
        "\n",
        "        # Her batch için, train_loss değişkenine batch'teki loss değeri ekleniyor ve train_count değişkeni de bir artırılıyor. Bu sayede, epoch boyunca ortalama train loss hesaplanabilecek\n",
        "        train_count += 1.0\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Her epoch sonrasında eğitim seti ve doğrulama seti için kayıp değerlerinin hesaplanması\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for inputs, labels in dataloader_valid:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "    model.train()\n",
        "\n",
        "    train_loss /= train_count\n",
        "    val_loss /= len(dataloader_valid)\n",
        "\n",
        "    print(\"Epoch\", epoch, \"Training loss\", train_loss,\"Validation Loss :\",val_loss)\n",
        "    list_train_loss.append(train_loss)\n",
        "    list_val_loss.append(val_loss)\n",
        "\n",
        "    #Early stopping yapıldı. Model, her epoch sonunda doğrulama verilerindeki kaybın en düşük olduğu durumda kaydedilir ve belirli bir sayıda epoch boyunca (patience) doğrulama kaybı azalmazsa eğitim sonlandırılır.\n",
        "    val_score = val_loss\n",
        "    if best_val_loss is None:\n",
        "        best_val_loss = val_score \n",
        "        torch.save(model.state_dict(), \"checkpoint.pt\")\n",
        "    elif best_val_loss < val_score: \n",
        "        #patience:mevcut doğruluk değeri ile en iyi kaydedilen doğruluk değeri arasındaki fark\n",
        "        patience_counter += 1\n",
        "        print(\"Earlystopping Patience Değeri:\", patience_counter)\n",
        "        if patience_counter == patience:\n",
        "            break\n",
        "    else:\n",
        "        best_val_loss = val_score\n",
        "        torch.save(model.state_dict(), \"checkpoint.pt\")\n",
        "        patience_counter = 0\n",
        "    \n",
        "# Bu kod bloğu eğitim sürecinde kaydedilen eğitim ve doğrulama (validation) kayıplarının grafiklerini çizdirir. \n",
        "# X ekseni epoch sayısını, y ekseni kayıp (loss) değerini gösterir. \n",
        "# Bu grafikler, modelin eğitim ve doğrulama performansını izlemek ve aşırı uydurmayı (overfitting) tespit etmek için kullanılabilir.\n",
        "plt.plot(list_train_loss, label=\"Training loss\")\n",
        "plt.plot(list_val_loss, label=\"Validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
        "model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "model.eval()\n",
        "predicts =[]\n",
        "real_labels = list()\n",
        "with torch.no_grad():\n",
        "    for inputs,label in dataloader_test:\n",
        "        outputs = model(inputs)\n",
        "        for out in outputs:\n",
        "            \n",
        "            predict = round(float(out.data))\n",
        "            predicts.append(predict)\n",
        "        real_labels.extend(label.tolist())\n",
        "\n",
        "from sklearn.metrics import f1_score,accuracy_score,classification_report\n",
        "print(\"Modelin doğruluk yüzdesi: {}\".format(accuracy_score(real_labels,predicts)))\n",
        "print(classification_report(real_labels,predicts))"
      ],
      "metadata": {
        "id": "SenNhq38cSeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "****"
      ],
      "metadata": {
        "id": "Mq8oEzhDc7gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.SORU İLE İLGİLİ KOD KISMI**"
      ],
      "metadata": {
        "id": "vJdTzZAUc-Kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verilerin önişleme adımlarını gerçekleştirerek bir makine öğrenimi modelinin eğitiminde kullanılmak üzere verileri hazırlar."
      ],
      "metadata": {
        "id": "i3oonj8hDSFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train.iloc[:,:-1]\n",
        "train_y = train.iloc[:,-1]\n",
        "\n",
        "test_x = test.iloc[:,:-1]\n",
        "test_y = test.iloc[:,-1]\n",
        "\n",
        "valid_x = valid.iloc[:,:-1]\n",
        "valid_y = valid.iloc[:,-1]\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "train_x = scaler.fit_transform(train_x)\n",
        "test_x = scaler.fit_transform(test_x)\n",
        "valid_x = scaler.fit_transform(valid_x)\n",
        "train_x = torch.tensor(np.array(train_x),dtype = torch.float32)\n",
        "train_y = torch.tensor(np.array(train_y),dtype = torch.float32).reshape(-1,1)\n",
        "dataset = [(train_x[i],train_y[i]) for i in range(len(train_x))]\n",
        "dataloader_train = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_x = torch.tensor(np.array(test_x),dtype = torch.float32)\n",
        "test_y = torch.tensor(np.array(test_y),dtype = torch.float32).reshape(-1,1)\n",
        "dataset = [(test_x[i],test_y[i]) for i in range(len(test_x))]\n",
        "dataloader_test = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=True)\n",
        "\n",
        "valid_x = torch.tensor(np.array(valid_x),dtype = torch.float32)\n",
        "valid_y = torch.tensor(np.array(valid_y),dtype = torch.float32).reshape(-1,1)\n",
        "dataset = [(valid_x[i],valid_y[i]) for i in range(len(valid_x))]\n",
        "dataloader_valid = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Ra1P96mSjL",
        "outputId": "7e7d9030-6802-48c0-803f-02e2d83d5184"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 29.8 ms (started: 2023-04-14 08:27:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm_8BxmKnecm",
        "outputId": "8dd75737-c7dc-4069-9cda-84dc55e9c17f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2214, 0.4320, 0.6650,  ..., 0.1498, 0.6552, 0.2077],\n",
              "        [0.7587, 0.0272, 0.6164,  ..., 0.5719, 0.2808, 0.4481],\n",
              "        [0.5299, 0.2477, 0.5780,  ..., 0.9358, 0.4532, 0.2896],\n",
              "        ...,\n",
              "        [0.1144, 0.0332, 0.5422,  ..., 0.1131, 0.5148, 0.2760],\n",
              "        [0.1418, 0.4562, 0.4194,  ..., 0.0765, 0.4089, 0.4481],\n",
              "        [0.2886, 0.3505, 0.5985,  ..., 0.2936, 0.3374, 0.0820]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.03 ms (started: 2023-04-14 08:27:35 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6**"
      ],
      "metadata": {
        "id": "rgdyyNHNu7Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autotime\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, weight_decay=0.01,dropout_prob=0.5):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.dropout1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.dropout2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def l2_regularization(self):\n",
        "        total_weight = 0.0\n",
        "        \n",
        "        for param in self.parameters():\n",
        "            total_weight += torch.sum(torch.square(param))\n",
        "        \n",
        "        return self.weight_decay * total_weight\n",
        "    \n",
        "    def loss(self, output, target):\n",
        "        ce_loss = F.binary_cross_entropy(output, target)\n",
        "        \n",
        "        # weight decay ile L2 regülarizasyonunun eklenmesi\n",
        "        l2_reg = self.l2_regularization()\n",
        "        \n",
        "        # toplam loss değerinin döndürülmesi\n",
        "        return ce_loss + l2_reg\n",
        "\n",
        "\n",
        "input_size = 13\n",
        "hidden_size1 = 100\n",
        "hidden_size2 = 50\n",
        "output_size = 1\n",
        "\n",
        "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay= 1e-6)\n",
        "\n",
        "list_train_loss, list_val_loss = [], []\n",
        "best_val_loss = None\n",
        "\n",
        "patience_counter = 0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_count = 0.0\n",
        "    for inputs, labels in dataloader_train:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_count += 1.0\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for inputs, labels in dataloader_valid:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    model.train()\n",
        "    train_loss /= train_count\n",
        "    val_loss /= len(dataloader_valid)\n",
        "    print(\"Epoch\", epoch, \"Training loss\", train_loss,\"Validation Loss :\",val_loss)\n",
        "\n",
        "    list_train_loss.append(train_loss)\n",
        "    list_val_loss.append(val_loss)\n",
        "\n",
        "    val_score = val_loss\n",
        "    if best_val_loss is None:\n",
        "        best_val_loss = val_score \n",
        "        torch.save(model.state_dict(), \"checkpoint.pt\")\n",
        "    elif best_val_loss < val_score: \n",
        "        patience_counter += 1\n",
        "        print(\"Earlystopping Patience Counter:\",patience_counter)\n",
        "        if patience_counter == patience:\n",
        "            break\n",
        "    else:\n",
        "        best_val_loss = val_score\n",
        "        torch.save(model.state_dict(), \"checkpoint.pt\") \n",
        "        patience_counter = 0\n",
        "    \n",
        "plt.plot(list_train_loss, label=\"Training loss\")\n",
        "plt.plot(list_val_loss, label=\"Validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
        "model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "model.eval()\n",
        "predicts =[]\n",
        "real_labels = list()\n",
        "with torch.no_grad():\n",
        "    for inputs,label in dataloader_test:\n",
        "        outputs = model(inputs)\n",
        "        for out in outputs:\n",
        "            \n",
        "            predict = round(float(out.data))\n",
        "            predicts.append(predict)\n",
        "        real_labels.extend(label.tolist())\n",
        "\n",
        "from sklearn.metrics import f1_score,accuracy_score,classification_report\n",
        "print(\"Accuracy score of this model: {}\".format(accuracy_score(real_labels,predicts)))\n",
        "print(classification_report(real_labels,predicts))"
      ],
      "metadata": {
        "id": "EZiFFvMvlErn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}